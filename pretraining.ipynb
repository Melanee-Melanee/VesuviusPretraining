{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vesuvius Pretraining\n",
    "Code to pretrain on Vesuvius unlabeled segments using Variance-Invariance-Covariance method with the lightly package for self-supervised training. \n",
    "\n",
    "based on this fantastic notebook https://www.kaggle.com/code/tanakar/2-5d-segmentaion-baseline-training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:01.573533Z",
     "iopub.status.busy": "2023-08-27T15:29:01.572747Z",
     "iopub.status.idle": "2023-08-27T15:29:09.967766Z",
     "shell.execute_reply": "2023-08-27T15:29:09.966916Z",
     "shell.execute_reply.started": "2023-08-27T15:29:01.573505Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "spacy 3.4.1 requires pydantic!=1.8,!=1.8.1,<1.10.0,>=1.7.4, but you have pydantic 1.10.12 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install wandb pytorch-lightning lightly -qU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:23.166133Z",
     "iopub.status.busy": "2023-08-27T15:29:23.165963Z",
     "iopub.status.idle": "2023-08-27T15:29:31.601562Z",
     "shell.execute_reply": "2023-08-27T15:29:31.600743Z",
     "shell.execute_reply.started": "2023-08-27T15:29:23.166116Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting timm\n",
      "  Downloading timm-0.9.5-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting warmup_scheduler\n",
      "  Downloading warmup_scheduler-0.3.tar.gz (2.1 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting segmentation_models_pytorch\n",
      "  Downloading segmentation_models_pytorch-0.3.3-py3-none-any.whl (106 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m106.7/106.7 kB\u001b[0m \u001b[31m35.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting albumentations\n",
      "  Downloading albumentations-1.3.1-py3-none-any.whl (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.7/125.7 kB\u001b[0m \u001b[31m43.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: huggingface-hub in /usr/local/lib/python3.9/dist-packages (from timm) (0.12.0)\n",
      "Requirement already satisfied: torch>=1.7 in /usr/local/lib/python3.9/dist-packages (from timm) (1.12.1+cu116)\n",
      "Collecting safetensors\n",
      "  Downloading safetensors-0.3.3-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.9/dist-packages (from timm) (5.4.1)\n",
      "Requirement already satisfied: torchvision in /usr/local/lib/python3.9/dist-packages (from timm) (0.13.1+cu116)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.9/dist-packages (from segmentation_models_pytorch) (9.2.0)\n",
      "Collecting pretrainedmodels==0.7.4\n",
      "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.9/dist-packages (from segmentation_models_pytorch) (4.64.1)\n",
      "Collecting timm\n",
      "  Downloading timm-0.9.2-py3-none-any.whl (2.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting efficientnet-pytorch==0.7.1\n",
      "  Downloading efficientnet_pytorch-0.7.1.tar.gz (21 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting munch\n",
      "  Downloading munch-4.0.0-py2.py3-none-any.whl (9.9 kB)\n",
      "Requirement already satisfied: scikit-image>=0.16.1 in /usr/local/lib/python3.9/dist-packages (from albumentations) (0.19.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from albumentations) (1.9.2)\n",
      "Requirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.9/dist-packages (from albumentations) (1.23.4)\n",
      "Collecting opencv-python-headless>=4.1.1\n",
      "  Downloading opencv_python_headless-4.8.0.76-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 MB\u001b[0m \u001b[31m38.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting qudida>=0.0.4\n",
      "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations) (4.4.0)\n",
      "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.9/dist-packages (from qudida>=0.0.4->albumentations) (1.1.2)\n",
      "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (2.25.0)\n",
      "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (3.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (2023.1.23.1)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (1.4.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image>=0.16.1->albumentations) (23.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.9/dist-packages (from torchvision->timm) (2.28.2)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from huggingface-hub->timm) (3.9.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->timm) (1.26.14)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/lib/python3/dist-packages (from requests->torchvision->timm) (2.8)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.9/dist-packages (from requests->torchvision->timm) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->torchvision->timm) (2019.11.28)\n",
      "Building wheels for collected packages: warmup_scheduler, efficientnet-pytorch, pretrainedmodels\n",
      "  Building wheel for warmup_scheduler (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for warmup_scheduler: filename=warmup_scheduler-0.3-py3-none-any.whl size=2966 sha256=b44026ac2964358b9bad6fb126a54455a5996eaa3f5bb44c2ccf3d2003ad3d33\n",
      "  Stored in directory: /root/.cache/pip/wheels/d1/b1/96/42c63380f9c322f577be6ba80cb7ab1bc1b28e10f74d95ba64\n",
      "  Building wheel for efficientnet-pytorch (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for efficientnet-pytorch: filename=efficientnet_pytorch-0.7.1-py3-none-any.whl size=16428 sha256=13167ca6e7f28f1cb57c6406951f52f3b65980fbb0ffa1e09c497ace286b3737\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/16/f1/5369d23a06852d5f083d23a1addf0904575f1296f71b412ac8\n",
      "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60943 sha256=f115ecfe44820d7d40afc275b805188bc5b0d1030a3417a0f0195ebeda15794d\n",
      "  Stored in directory: /root/.cache/pip/wheels/1f/9b/f5/9ccf39b50bc437986145107e2ced70a6fab622cf23e4795aa5\n",
      "Successfully built warmup_scheduler efficientnet-pytorch pretrainedmodels\n",
      "Installing collected packages: warmup_scheduler, safetensors, opencv-python-headless, munch, efficientnet-pytorch, timm, qudida, pretrainedmodels, segmentation_models_pytorch, albumentations\n",
      "Successfully installed albumentations-1.3.1 efficientnet-pytorch-0.7.1 munch-4.0.0 opencv-python-headless-4.8.0.76 pretrainedmodels-0.7.4 qudida-0.0.4 safetensors-0.3.3 segmentation_models_pytorch-0.3.3 timm-0.9.2 warmup_scheduler-0.3\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install timm warmup_scheduler segmentation_models_pytorch albumentations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:09.970661Z",
     "iopub.status.busy": "2023-08-27T15:29:09.970441Z",
     "iopub.status.idle": "2023-08-27T15:29:12.817866Z",
     "shell.execute_reply": "2023-08-27T15:29:12.816972Z",
     "shell.execute_reply.started": "2023-08-27T15:29:09.970640Z"
    }
   },
   "outputs": [],
   "source": [
    "import os.path as osp\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import argparse\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, StochasticWeightAveraging\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, log_loss\n",
    "import pickle\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import warnings\n",
    "import sys\n",
    "import pandas as pd\n",
    "import gc\n",
    "import sys\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "from contextlib import contextmanager\n",
    "from collections import defaultdict, Counter\n",
    "import cv2\n",
    "\n",
    "import scipy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.auto import tqdm\n",
    "from functools import partial\n",
    "\n",
    "import importlib\n",
    "\n",
    "from torch.optim import Adam, SGD, AdamW\n",
    "from ema_pytorch import EMA\n",
    "\n",
    "import datetime\n",
    "import math\n",
    "import time\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n",
    "from warmup_scheduler import GradualWarmupScheduler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:15.670756Z",
     "iopub.status.busy": "2023-08-27T15:29:15.670139Z",
     "iopub.status.idle": "2023-08-27T15:29:22.963856Z",
     "shell.execute_reply": "2023-08-27T15:29:22.962981Z",
     "shell.execute_reply.started": "2023-08-27T15:29:15.670727Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ········································\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Log in to your W&B account\n",
    "import wandb\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:22.970807Z",
     "iopub.status.busy": "2023-08-27T15:29:22.970450Z",
     "iopub.status.idle": "2023-08-27T15:29:23.161597Z",
     "shell.execute_reply": "2023-08-27T15:29:23.160983Z",
     "shell.execute_reply.started": "2023-08-27T15:29:22.970779Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:31.603356Z",
     "iopub.status.busy": "2023-08-27T15:29:31.602723Z",
     "iopub.status.idle": "2023-08-27T15:29:32.631300Z",
     "shell.execute_reply": "2023-08-27T15:29:32.630437Z",
     "shell.execute_reply.started": "2023-08-27T15:29:31.603329Z"
    }
   },
   "outputs": [],
   "source": [
    "import segmentation_models_pytorch as smp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:32.634954Z",
     "iopub.status.busy": "2023-08-27T15:29:32.634033Z",
     "iopub.status.idle": "2023-08-27T15:29:35.810992Z",
     "shell.execute_reply": "2023-08-27T15:29:35.810032Z",
     "shell.execute_reply.started": "2023-08-27T15:29:32.634926Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: warmup_scheduler in /usr/local/lib/python3.9/dist-packages (0.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install warmup_scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:35.896142Z",
     "iopub.status.busy": "2023-08-27T15:29:35.895956Z",
     "iopub.status.idle": "2023-08-27T15:29:35.907547Z",
     "shell.execute_reply": "2023-08-27T15:29:35.906781Z",
     "shell.execute_reply.started": "2023-08-27T15:29:35.896124Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set dataset path\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/albumentations/augmentations/dropout/cutout.py:49: FutureWarning: Cutout has been deprecated. Please use CoarseDropout\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "class CFG:\n",
    "    # ============== comp exp name =============\n",
    "    comp_name = 'vesuvius'\n",
    "\n",
    "    # comp_dir_path = './'\n",
    "    comp_dir_path = './'\n",
    "    comp_folder_name = './'\n",
    "    # comp_dataset_path = f'{comp_dir_path}datasets/{comp_folder_name}/'\n",
    "    comp_dataset_path = f'./'\n",
    "    \n",
    "    exp_name = 'pretraining_30'\n",
    "\n",
    "    # ============== pred target =============\n",
    "    target_size = 1\n",
    "\n",
    "    \n",
    "\n",
    "    in_chans = 20 # 65\n",
    "    encoder_depth=5\n",
    "    # ============== training cfg =============\n",
    "    size = 128\n",
    "    tile_size = 128\n",
    "    stride = tile_size // 4\n",
    "\n",
    "    train_batch_size = 150 # 32\n",
    "    valid_batch_size = train_batch_size*2\n",
    "    use_amp = True\n",
    "\n",
    "    scheduler = 'GradualWarmupSchedulerV2'\n",
    "    # scheduler = 'CosineAnnealingLR'\n",
    "    epochs = 35 # 30\n",
    "\n",
    "    # adamW warmupあり\n",
    "    warmup_factor = 10\n",
    "    # lr = 1e-4 / warmup_factor\n",
    "    lr = 1e-4 / warmup_factor\n",
    "\n",
    "\n",
    "   \n",
    "    min_lr = 1e-6\n",
    "    weight_decay = 1e-6\n",
    "    max_grad_norm = 5\n",
    "\n",
    "    num_workers = 12\n",
    "\n",
    "    seed = 42\n",
    "\n",
    "    # ============== set dataset path =============\n",
    "    print('set dataset path')\n",
    "\n",
    "    outputs_path = f'./outputs/{comp_name}/{exp_name}/'\n",
    "\n",
    "    submission_dir = outputs_path + 'submissions/'\n",
    "    submission_path = submission_dir + f'submission_{exp_name}.csv'\n",
    "\n",
    "    model_dir = outputs_path + \\\n",
    "        f'{comp_name}-models/'\n",
    "\n",
    "    figures_dir = outputs_path + 'figures/'\n",
    "\n",
    "    log_dir = outputs_path + 'logs/'\n",
    "    log_path = log_dir + f'{exp_name}.txt'\n",
    "\n",
    "    # ============== augmentation =============\n",
    "    train_aug_list = [\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5),\n",
    "        A.RandomRotate90(p=0.5),\n",
    "\n",
    "        A.ShiftScaleRotate(rotate_limit=45,shift_limit=0.15,scale_limit=0.15,p=0.5),\n",
    "        A.OneOf([\n",
    "                A.GaussNoise(var_limit=[10, 50]),\n",
    "                A.GaussianBlur(),\n",
    "                A.MotionBlur(),\n",
    "                ], p=0.4),\n",
    "        A.GridDistortion(num_steps=2, distort_limit=0.3, p=0.4),\n",
    "        A.CoarseDropout(max_holes=4, max_width=int(size * 0.06), max_height=int(size * 0.06), \n",
    "                        mask_fill_value=0, p=0.5),\n",
    "        A.Cutout(max_h_size=int(size * 0.15),\n",
    "                 max_w_size=int(size * 0.15), num_holes=1, p=0.5),\n",
    "        A.Normalize(\n",
    "            mean= [0] * in_chans,\n",
    "            std= [1] * in_chans\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "        \n",
    "    ]\n",
    "    global_aug_list=[\n",
    "        A.Resize(size, size),\n",
    "        A.ShiftScaleRotate(rotate_limit=0,shift_limit=0.25,scale_limit=0.25,p=0.75),\n",
    "    ]\n",
    "    valid_aug_list = [\n",
    "        A.Resize(size, size),\n",
    "        A.Normalize(\n",
    "            mean= [0] * in_chans,\n",
    "            std= [1] * in_chans\n",
    "        ),\n",
    "        ToTensorV2(transpose_mask=True),\n",
    "    ]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## helper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:35.908482Z",
     "iopub.status.busy": "2023-08-27T15:29:35.908292Z",
     "iopub.status.idle": "2023-08-27T15:29:35.912606Z",
     "shell.execute_reply": "2023-08-27T15:29:35.911977Z",
     "shell.execute_reply.started": "2023-08-27T15:29:35.908462Z"
    }
   },
   "outputs": [],
   "source": [
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:35.913440Z",
     "iopub.status.busy": "2023-08-27T15:29:35.913258Z",
     "iopub.status.idle": "2023-08-27T15:29:35.918256Z",
     "shell.execute_reply": "2023-08-27T15:29:35.917692Z",
     "shell.execute_reply.started": "2023-08-27T15:29:35.913422Z"
    }
   },
   "outputs": [],
   "source": [
    "def init_logger(log_file):\n",
    "    from logging import getLogger, INFO, FileHandler, Formatter, StreamHandler\n",
    "    logger = getLogger(__name__)\n",
    "    logger.setLevel(INFO)\n",
    "    handler1 = StreamHandler()\n",
    "    handler1.setFormatter(Formatter(\"%(message)s\"))\n",
    "    handler2 = FileHandler(filename=log_file)\n",
    "    handler2.setFormatter(Formatter(\"%(message)s\"))\n",
    "    logger.addHandler(handler1)\n",
    "    logger.addHandler(handler2)\n",
    "    return logger\n",
    "\n",
    "def set_seed(seed=None, cudnn_deterministic=True):\n",
    "    if seed is None:\n",
    "        seed = 42\n",
    "\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = cudnn_deterministic\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:35.919525Z",
     "iopub.status.busy": "2023-08-27T15:29:35.919312Z",
     "iopub.status.idle": "2023-08-27T15:29:35.922849Z",
     "shell.execute_reply": "2023-08-27T15:29:35.922164Z",
     "shell.execute_reply.started": "2023-08-27T15:29:35.919506Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_dirs(cfg):\n",
    "    for dir in [cfg.model_dir, cfg.figures_dir, cfg.submission_dir, cfg.log_dir]:\n",
    "        os.makedirs(dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:35.923744Z",
     "iopub.status.busy": "2023-08-27T15:29:35.923557Z",
     "iopub.status.idle": "2023-08-27T15:29:35.927028Z",
     "shell.execute_reply": "2023-08-27T15:29:35.926320Z",
     "shell.execute_reply.started": "2023-08-27T15:29:35.923725Z"
    }
   },
   "outputs": [],
   "source": [
    "def cfg_init(cfg, mode='train'):\n",
    "    set_seed(cfg.seed)\n",
    "    if mode == 'train':\n",
    "        make_dirs(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:35.927901Z",
     "iopub.status.busy": "2023-08-27T15:29:35.927724Z",
     "iopub.status.idle": "2023-08-27T15:29:35.960133Z",
     "shell.execute_reply": "2023-08-27T15:29:35.958370Z",
     "shell.execute_reply.started": "2023-08-27T15:29:35.927883Z"
    }
   },
   "outputs": [],
   "source": [
    "cfg_init(CFG)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:35.961364Z",
     "iopub.status.busy": "2023-08-27T15:29:35.961158Z",
     "iopub.status.idle": "2023-08-27T15:29:35.973737Z",
     "shell.execute_reply": "2023-08-27T15:29:35.973147Z",
     "shell.execute_reply.started": "2023-08-27T15:29:35.961344Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "def read_image_mask(fragment_id,start_idx=14,end_idx=36):\n",
    "\n",
    "    images = []\n",
    "\n",
    "    # idxs = range(65)\n",
    "    mid = 65 // 2\n",
    "    start = mid - CFG.in_chans // 2\n",
    "    end = mid + CFG.in_chans // 2\n",
    "    idxs = range(start_idx, end_idx)\n",
    "\n",
    "    for i in tqdm(idxs):\n",
    "        \n",
    "        image = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/surface_volume/{i:02}.tif\", 0)\n",
    "\n",
    "        pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
    "        pad1 = (CFG.tile_size - image.shape[1] % CFG.tile_size)\n",
    "\n",
    "        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "        \n",
    "        image = cv2.resize(image, (image.shape[1]//2,image.shape[0]//2), interpolation = cv2.INTER_AREA)\n",
    "        images.append(image)\n",
    "    images = np.stack(images, axis=2)\n",
    "    mask = cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/inklabels.png\", 0)\n",
    "    mask = np.pad(mask, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "    fragment_mask=cv2.imread(CFG.comp_dataset_path + f\"train/{fragment_id}/mask.png\", 0)\n",
    "    fragment_mask = np.pad(fragment_mask, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "    kernel = np.ones((16,16),np.uint8)\n",
    "    fragment_mask = cv2.erode(fragment_mask,kernel,iterations = 1)\n",
    "    mask = mask.astype('float32')\n",
    "    mask = cv2.resize(mask, (mask.shape[1]//2,mask.shape[0]//2), interpolation = cv2.INTER_AREA)\n",
    "    fragment_mask = cv2.resize(fragment_mask, (fragment_mask.shape[1]//2,fragment_mask.shape[0]//2), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "    mask/=255\n",
    "    return images, mask,fragment_mask\n",
    "from scipy import ndimage\n",
    "def read_image_mask_scrolls(fragment_id,start_idx=14,end_idx=36):\n",
    "\n",
    "    images = []\n",
    "\n",
    "    # idxs = range(65)\n",
    "    mid = 65 // 2\n",
    "    start = mid - CFG.in_chans // 2\n",
    "    end = mid + CFG.in_chans // 2\n",
    "    idxs = range(start_idx, end_idx)\n",
    "\n",
    "    for i in idxs:\n",
    "        \n",
    "        image = cv2.imread(f\"./scrolls_all/{fragment_id}/layers/{i:02}.tif\", 0)\n",
    "\n",
    "        pad0 = (CFG.tile_size - image.shape[0] % CFG.tile_size)\n",
    "        pad1 = (CFG.tile_size - image.shape[1] % CFG.tile_size)\n",
    "\n",
    "        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "        images.append(image)\n",
    "    images = np.stack(images, axis=2)\n",
    "    fragment_mask=None\n",
    "    if os.path.exists(f'./scrolls_all/{fragment_id}/{fragment_id}_mask.png'):\n",
    "        fragment_mask=cv2.imread(CFG.comp_dataset_path + f\"scrolls_all/{fragment_id}/{fragment_id}_mask.png\", 0)\n",
    "        fragment_mask = np.pad(fragment_mask, [(0, pad0), (0, pad1)], constant_values=0)\n",
    "        kernel = np.ones((16,16),np.uint8)\n",
    "        fragment_mask = cv2.erode(fragment_mask,kernel,iterations = 1)\n",
    "        # fragment_mask = cv2.rotate(fragment_mask, cv2.ROTATE_90_CLOCKWISE)\n",
    "\n",
    "    # mask = 2*(mask/255 - 0.5)\n",
    "    return images,fragment_mask\n",
    "def read_image_scrolls_stats(fragment_id,start_idx=16,end_idx=32):\n",
    "\n",
    "    images = []\n",
    "\n",
    "    # idxs = range(65)\n",
    "    mid = 65 // 2\n",
    "    start = mid - 16 // 2\n",
    "    end = mid + 16// 2\n",
    "    idxs = range(start_idx, end_idx)\n",
    "    means=[]\n",
    "    stds=[]\n",
    "    for i in idxs:\n",
    "        \n",
    "        image = cv2.imread(f\"./scrolls_all/{fragment_id}/layers/{i:02}.tif\", 0)\n",
    "        pad0 = (64- image.shape[0] % 64)\n",
    "        pad1 = (64- image.shape[1] %64)\n",
    "\n",
    "        image = np.pad(image, [(0, pad0), (0, pad1)], constant_values=0).astype(np.uint8)\n",
    "        means.append(image.mean())\n",
    "        stds.append(image.std())\n",
    "    return np.array(means),np.array(stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:35.974676Z",
     "iopub.status.busy": "2023-08-27T15:29:35.974489Z",
     "iopub.status.idle": "2023-08-27T15:29:35.980144Z",
     "shell.execute_reply": "2023-08-27T15:29:35.979574Z",
     "shell.execute_reply.started": "2023-08-27T15:29:35.974658Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_img_splits(fragment_id,s,e):\n",
    "    images = []\n",
    "    masks = []\n",
    "    xyxys = []\n",
    "    image, mask,fragment_mask = read_image_mask(fragment_id,s,e)\n",
    "    x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
    "    y1_list = list(range(0, image.shape[0]-CFG.tile_size+1, CFG.stride))\n",
    "    for y1 in y1_list:\n",
    "        for x1 in x1_list:\n",
    "            y2 = y1 + CFG.tile_size\n",
    "            x2 = x1 + CFG.tile_size\n",
    "            images.append(image[y1:y2, x1:x2])\n",
    "            masks.append(mask[y1:y2, x1:x2, None])\n",
    "            xyxys.append([x1, y1, x2, y2])\n",
    "    test_dataset = CustomDatasetTest(images,np.stack(xyxys), CFG, transform=get_transforms(data='valid', cfg=CFG))\n",
    "\n",
    "    test_loader = DataLoader(test_dataset,\n",
    "                              batch_size=CFG.valid_batch_size,\n",
    "                              shuffle=False,\n",
    "                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False,\n",
    "                              )\n",
    "    return test_loader, np.stack(xyxys),mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:35.981247Z",
     "iopub.status.busy": "2023-08-27T15:29:35.981058Z",
     "iopub.status.idle": "2023-08-27T15:29:35.987525Z",
     "shell.execute_reply": "2023-08-27T15:29:35.986949Z",
     "shell.execute_reply.started": "2023-08-27T15:29:35.981230Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_train_valid_dataset(frags):\n",
    "    train_images = []\n",
    "    train_masks = []\n",
    "\n",
    "    valid_images = []\n",
    "    valid_masks = []\n",
    "    valid_xyxys = []\n",
    "\n",
    "    for fragment_id in range(4, 5):\n",
    "\n",
    "        image, _,fragment_mask = read_image_mask(fragment_id)\n",
    "\n",
    "        x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
    "        y1_list = list(range(0, image.shape[0]-CFG.tile_size+1, CFG.stride))\n",
    "\n",
    "        for y1 in y1_list:\n",
    "            for x1 in x1_list:\n",
    "                y2 = y1 + CFG.tile_size\n",
    "                x2 = x1 + CFG.tile_size\n",
    "\n",
    "                if not np.any(fragment_mask[y1:y2, x1:x2]==0) :\n",
    "                    train_images.append(image[y1:y2, x1:x2])\n",
    "\n",
    "    for fragment_id in tqdm(frags):\n",
    "        image,fragment_mask = read_image_mask_scrolls(fragment_id)\n",
    "        x1_list = list(range(0, image.shape[1]-CFG.tile_size+1, CFG.stride))\n",
    "        y1_list = list(range(0, image.shape[0]-CFG.tile_size+1, CFG.stride))\n",
    "\n",
    "        for y1 in y1_list:\n",
    "            for x1 in x1_list:\n",
    "                y2 = y1 + CFG.tile_size\n",
    "                x2 = x1 + CFG.tile_size\n",
    "        \n",
    "                if fragment_mask is not None and not np.any(fragment_mask[y1:y2, x1:x2]==0) :\n",
    "                    train_images.append(image[y1:y2, x1:x2])\n",
    "                elif not np.all(image[y1:y2, x1:x2])==0:\n",
    "                    train_images.append(image[y1:y2, x1:x2])\n",
    "\n",
    "    return train_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:29:35.988494Z",
     "iopub.status.busy": "2023-08-27T15:29:35.988316Z",
     "iopub.status.idle": "2023-08-27T15:33:22.232759Z",
     "shell.execute_reply": "2023-08-27T15:33:22.232018Z",
     "shell.execute_reply.started": "2023-08-27T15:29:35.988476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e4e0663e90a43f4a0aefed9fafd29b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f25ed9bda3c404ab6e7d9e54b77f934",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/38 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_images = get_train_valid_dataset(os.listdir('./scrolls_all'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:33:22.233957Z",
     "iopub.status.busy": "2023-08-27T15:33:22.233753Z",
     "iopub.status.idle": "2023-08-27T15:33:22.436338Z",
     "shell.execute_reply": "2023-08-27T15:33:22.435600Z",
     "shell.execute_reply.started": "2023-08-27T15:33:22.233936Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:33:22.444451Z",
     "iopub.status.busy": "2023-08-27T15:33:22.444273Z",
     "iopub.status.idle": "2023-08-27T15:33:22.447617Z",
     "shell.execute_reply": "2023-08-27T15:33:22.446934Z",
     "shell.execute_reply.started": "2023-08-27T15:33:22.444434Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import cv2\n",
    "import torch\n",
    "import os\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from albumentations import ImageOnlyTransform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:33:22.448397Z",
     "iopub.status.busy": "2023-08-27T15:33:22.448222Z",
     "iopub.status.idle": "2023-08-27T15:33:22.454232Z",
     "shell.execute_reply": "2023-08-27T15:33:22.453525Z",
     "shell.execute_reply.started": "2023-08-27T15:33:22.448379Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_transforms(data, cfg):\n",
    "    if data == 'train':\n",
    "        aug = A.Compose(cfg.train_aug_list)\n",
    "    elif data == 'valid':\n",
    "        aug = A.Compose(cfg.global_aug_list)\n",
    "\n",
    "    # print(aug)\n",
    "    return aug\n",
    "\n",
    "class CustomDatasetPretraining(Dataset):\n",
    "    def __init__(self, images, cfg, transform=None,global_transform=None):\n",
    "        self.images = images\n",
    "        self.cfg = cfg\n",
    "        self.transform = transform\n",
    "        self.global_transform=global_transform\n",
    "    def __len__(self):\n",
    "        # return len(self.df)\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx]\n",
    "        offset=random.choice([0,1,1,2])\n",
    "        # offset=1\n",
    "        stretch_offset=random.choice([0,1,1,2,3,4])\n",
    "        pixel_offset=0\n",
    "        pixel_offset=random.choice([0,0,0,5,10])\n",
    "        image=image[:,:,offset:offset+self.cfg.in_chans]+pixel_offset\n",
    "        if self.transform:\n",
    "            data = self.transform(image=image)\n",
    "            image1 = data['image'].unsqueeze(0)\n",
    "            data2= self.transform(image=image)\n",
    "            image2= data2['image'].unsqueeze(0)\n",
    "        return image1,image2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:33:22.454969Z",
     "iopub.status.busy": "2023-08-27T15:33:22.454787Z",
     "iopub.status.idle": "2023-08-27T15:33:22.458953Z",
     "shell.execute_reply": "2023-08-27T15:33:22.458364Z",
     "shell.execute_reply.started": "2023-08-27T15:33:22.454952Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = CustomDatasetPretraining(\n",
    "    train_images, CFG, transform=get_transforms(data='train', cfg=CFG),global_transform=get_transforms(data='valid', cfg=CFG))\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=CFG.train_batch_size,\n",
    "                          shuffle=True,\n",
    "                          num_workers=CFG.num_workers, pin_memory=True, drop_last=True,\n",
    "                          )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:33:22.468398Z",
     "iopub.status.busy": "2023-08-27T15:33:22.468232Z",
     "iopub.status.idle": "2023-08-27T15:33:23.284175Z",
     "shell.execute_reply": "2023-08-27T15:33:23.283365Z",
     "shell.execute_reply.started": "2023-08-27T15:33:22.468381Z"
    }
   },
   "outputs": [],
   "source": [
    "from resnetall import generate_model\n",
    "# from lightly.loss import NegativeCosineSimilarity\n",
    "from lightly.models.modules import SimSiamPredictionHead, SimSiamProjectionHead\n",
    "from lightly.utils.debug import std_of_l2_normalized\n",
    "import copy\n",
    "\n",
    "from lightly.loss.vicreg_loss import VICRegLoss\n",
    "from lightly.loss import NegativeCosineSimilarity\n",
    "from lightly.models.modules import BYOLPredictionHead, BYOLProjectionHead\n",
    "from lightly.models.utils import deactivate_requires_grad, update_momentum\n",
    "from lightly.transforms.simclr_transform import SimCLRTransform\n",
    "from lightly.utils.scheduler import cosine_schedule\n",
    "\n",
    "## The projection head is the same as the Barlow Twins one\n",
    "from lightly.models.modules import BarlowTwinsProjectionHead\n",
    "def normalization(x):\n",
    "    \"\"\"input.shape=(batch,f1,f2,...)\"\"\"\n",
    "    #[batch,f1,f2]->dim[1,2]\n",
    "    dim=list(range(1,x.ndim))\n",
    "    mean=x.mean(dim=dim,keepdim=True)\n",
    "    std=x.std(dim=dim,keepdim=True)\n",
    "    return (x-mean)/(std+1e-9)\n",
    "class BYOL(pl.LightningModule):\n",
    "    def __init__(self,model_depth=50):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        self.backbone=generate_model(model_depth=self.hparams.model_depth, n_input_channels=1,n_classes=512,no_max_pool=True)\n",
    "        self.projection_head = BYOLProjectionHead(512, 1024, 256)\n",
    "        self.prediction_head = BYOLPredictionHead(256, 1024, 256)\n",
    "\n",
    "        self.backbone_momentum = copy.deepcopy(self.backbone)\n",
    "        self.projection_head_momentum = copy.deepcopy(self.projection_head)\n",
    "\n",
    "        deactivate_requires_grad(self.backbone_momentum)\n",
    "        deactivate_requires_grad(self.projection_head_momentum)\n",
    "\n",
    "        self.criterion = NegativeCosineSimilarity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(y)\n",
    "        p = self.prediction_head(z)\n",
    "        return p\n",
    "\n",
    "    def forward_momentum(self, x):\n",
    "        y = self.backbone_momentum(x).flatten(start_dim=1)\n",
    "        z = self.projection_head_momentum(y)\n",
    "        z = z.detach()\n",
    "        return z\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        momentum = cosine_schedule(self.current_epoch, 10, 0.996, 1)\n",
    "        update_momentum(self.backbone, self.backbone_momentum, m=momentum)\n",
    "        update_momentum(self.projection_head, self.projection_head_momentum, m=momentum)\n",
    "        x0, x1 = batch\n",
    "        p0 = self.forward(x0)\n",
    "        z0 = self.forward_momentum(x0)\n",
    "        p1 = self.forward(x1)\n",
    "        z1 = self.forward_momentum(x1)\n",
    "        loss = 0.5 * (self.criterion(p0, z1) + self.criterion(p1, z0))\n",
    "        std_rep=std_of_l2_normalized(p0)\n",
    "\n",
    "        self.log(\"train/NegativeCS\", loss,on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train/STD_of_repr\", std_rep,on_step=True, on_epoch=True, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer=torch.optim.SGD(\n",
    "            self.parameters(),\n",
    "            lr=0.005,\n",
    "            momentum=0.9,\n",
    "            weight_decay=2e-6,\n",
    "            nesterov=True,\n",
    "        ) \n",
    "\n",
    "        scheduler = get_scheduler(CFG, optimizer)\n",
    "        return [optimizer],[scheduler]    \n",
    "class VICREGPLModel(pl.LightningModule):\n",
    "    def __init__(self,model_depth=50):\n",
    "        super(RegressionPLModel, self).__init__()\n",
    "\n",
    "        self.save_hyperparameters()\n",
    "        self.backbone=generate_model(model_depth=self.hparams.model_depth, n_input_channels=1,n_classes=512,forward_features=False)\n",
    "        self.projection_head = BarlowTwinsProjectionHead(512, 256, 512)\n",
    "        self.criterion = VICRegLoss(nu_param=5.0)\n",
    "        self.normalization=nn.InstanceNorm3d(num_features=1)\n",
    "    def forward(self, x):\n",
    "        x=self.normalization(x)\n",
    "        x = self.backbone(x).flatten(start_dim=1)\n",
    "        z = self.projection_head(x)\n",
    "        return z\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x0, x1 = batch\n",
    "        z0 = self.forward(x0)\n",
    "        z1 = self.forward(x1)\n",
    "        loss = self.criterion(z0, z1)\n",
    "        std_rep=std_of_l2_normalized(z0)\n",
    "\n",
    "        self.log(\"train/VICREGloss\", loss,on_step=True, on_epoch=True, prog_bar=True)\n",
    "        self.log(\"train/STD_of_repr\", std_rep,on_step=True, on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "\n",
    "        optimizer=torch.optim.SGD(\n",
    "            self.parameters(),\n",
    "            lr=0.05,\n",
    "            momentum=0.9,\n",
    "            weight_decay=5e-5,\n",
    "            nesterov=True,\n",
    "        ) \n",
    "\n",
    "        scheduler = get_scheduler(CFG, optimizer)\n",
    "        return [optimizer],[scheduler]\n",
    "\n",
    "class GradualWarmupSchedulerV2(GradualWarmupScheduler):\n",
    "    \"\"\"\n",
    "    https://www.kaggle.com/code/underwearfitting/single-fold-training-of-resnet200d-lb0-965\n",
    "    \"\"\"\n",
    "    def __init__(self, optimizer, multiplier, total_epoch, after_scheduler=None):\n",
    "        super(GradualWarmupSchedulerV2, self).__init__(\n",
    "            optimizer, multiplier, total_epoch, after_scheduler)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if self.last_epoch > self.total_epoch:\n",
    "            if self.after_scheduler:\n",
    "                if not self.finished:\n",
    "                    self.after_scheduler.base_lrs = [\n",
    "                        base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "                    self.finished = True\n",
    "                return self.after_scheduler.get_lr()\n",
    "            return [base_lr * self.multiplier for base_lr in self.base_lrs]\n",
    "        if self.multiplier == 1.0:\n",
    "            return [base_lr * (float(self.last_epoch) / self.total_epoch) for base_lr in self.base_lrs]\n",
    "        else:\n",
    "            return [base_lr * ((self.multiplier - 1.) * self.last_epoch / self.total_epoch + 1.) for base_lr in self.base_lrs]\n",
    "\n",
    "def get_scheduler(cfg, optimizer):\n",
    "    scheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
    "        optimizer, cfg.epochs, eta_min=1e-4)\n",
    "    scheduler = GradualWarmupSchedulerV2(\n",
    "        optimizer, multiplier=10, total_epoch=1, after_scheduler=scheduler_cosine)\n",
    "\n",
    "    return scheduler\n",
    "\n",
    "def scheduler_step(scheduler, avg_val_loss, epoch):\n",
    "    scheduler.step(epoch)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:33:23.315824Z",
     "iopub.status.busy": "2023-08-27T15:33:23.315600Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mjoenader\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.8"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20230827_153324-cuzene1r</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/joenader/vesivus/runs/cuzene1r' target=\"_blank\">pretraining_50</a></strong> to <a href='https://wandb.ai/joenader/vesivus' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/joenader/vesivus' target=\"_blank\">https://wandb.ai/joenader/vesivus</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/joenader/vesivus/runs/cuzene1r' target=\"_blank\">https://wandb.ai/joenader/vesivus/runs/cuzene1r</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/callbacks/model_checkpoint.py:617: UserWarning: Checkpoint directory /notebooks/outputs/vesuvius/pretraining_30/vesuvius-models exists and is not empty.\n",
      "  rank_zero_warn(f\"Checkpoint directory {dirpath} exists and is not empty.\")\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name            | Type                      | Params\n",
      "--------------------------------------------------------------\n",
      "0 | backbone        | ResNet                    | 47.2 M\n",
      "1 | projection_head | BarlowTwinsProjectionHead | 329 K \n",
      "2 | criterion       | VICRegLoss                | 0     \n",
      "3 | normalization   | InstanceNorm3d            | 0     \n",
      "--------------------------------------------------------------\n",
      "47.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "47.5 M    Total params\n",
      "190.134   Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f0b2ff33ce74d9b9e7ca115bb3424b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/dist-packages/torch/optim/lr_scheduler.py:728: UserWarning: To get the last learning rate computed by the scheduler, please use `get_last_lr()`.\n",
      "  warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
      "/usr/local/lib/python3.9/dist-packages/pytorch_lightning/trainer/call.py:53: UserWarning: Detected KeyboardInterrupt, attempting graceful shutdown...\n",
      "  rank_zero_warn(\"Detected KeyboardInterrupt, attempting graceful shutdown...\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# torch.multiprocessing.set_start_method('spawn')\n",
    "for di,depth in enumerate([50]):\n",
    "    torch.set_float32_matmul_precision('medium')\n",
    "    wandb_logger = WandbLogger(project=\"vesivus\",name=f'pretraining_{depth}')\n",
    "    model=VICREGPLModel(model_depth=depth)\n",
    "    # wandb_logger.watch(model, log=\"all\", log_freq=200)\n",
    "    trainer = pl.Trainer(\n",
    "        max_epochs=35,\n",
    "        accelerator=\"gpu\",\n",
    "        # strategy='auto',\n",
    "        devices=1,\n",
    "        logger=wandb_logger,\n",
    "        default_root_dir=\"./models\",\n",
    "        accumulate_grad_batches=2,\n",
    "        precision='16-mixed',\n",
    "        gradient_clip_val=1.0,\n",
    "        gradient_clip_algorithm=\"norm\",\n",
    "        callbacks=[ModelCheckpoint(filename=f'round2_{depth}'+'{epoch}',dirpath=CFG.model_dir,monitor='train/VICREGloss',save_top_k=50,mode='min',every_n_epochs=1),\n",
    "                  StochasticWeightAveraging(swa_lrs=1e-2)]\n",
    "    )\n",
    "    trainer.fit(model=model, train_dataloaders=train_loader)\n",
    "    #ckpt_path=CFG.model_dir+'round2_50epoch=9.ckpt'\n",
    "    wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code for plotting CKA similarity between the models representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:33:23.298990Z",
     "iopub.status.busy": "2023-08-27T15:33:23.298819Z",
     "iopub.status.idle": "2023-08-27T15:33:23.302796Z",
     "shell.execute_reply": "2023-08-27T15:33:23.302157Z",
     "shell.execute_reply.started": "2023-08-27T15:33:23.298972Z"
    }
   },
   "outputs": [],
   "source": [
    "# ckpt_dirs=[\n",
    "# './outputs/vesuvius/pretraining_28/vesuvius-models/round2_50epoch=6.ckpt',\n",
    "# './outputs/vesuvius/pretraining_28/vesuvius-models/round2_50epoch=12.ckpt',\n",
    "# './outputs/vesuvius/pretraining_28/vesuvius-models/round2_50epoch=15.ckpt',\n",
    "# './outputs/vesuvius/pretraining_28/vesuvius-models/round2_50epoch=17.ckpt',\n",
    "# './outputs/vesuvius/pretraining_28/vesuvius-models/round2_50epoch=20.ckpt',\n",
    "# './outputs/vesuvius/pretraining_28/vesuvius-models/round2_50epoch=23.ckpt',\n",
    "# ]\n",
    "# from cka_utils import *\n",
    "# from tqdm.notebook import tqdm\n",
    "\n",
    "# # ckpt_dirs=sorted([os.path.join(CFG.model_dir,model_path) for model_path in os.listdir(CFG.model_dir) if '.ckpt' in model_path])\n",
    "# models=[RegressionPLModel.load_from_checkpoint(path) for path in ckpt_dirs]\n",
    "# models=[m.eval().cuda() for m in models]\n",
    "# n_models=len(models)\n",
    "\n",
    "# embeddings=np.zeros((n_models,512,512))\n",
    "# for i in tqdm(range(512)):\n",
    "#     x1,x2=train_dataset[i]\n",
    "#     x=x1.cuda().unsqueeze(0)\n",
    "#     for mi,model in enumerate(models):\n",
    "#         embeddings[mi,i,:]=model(x).detach().cpu().numpy()\n",
    "# import seaborn as sns\n",
    "# ckas=np.zeros((n_models,n_models))\n",
    "# for i in range(n_models):\n",
    "#     for j in range(n_models):\n",
    "#         if i==j:\n",
    "#             continue\n",
    "#         ckas[i,j]=cka(gram_rbf(embeddings[i], 0.5), gram_rbf(embeddings[j], 0.5))\n",
    "# ckas_lin=np.zeros((n_models,n_models))\n",
    "# for i in range(n_models):\n",
    "#     for j in range(n_models):\n",
    "#         if i==j:\n",
    "#             continue\n",
    "#         ckas_lin[i,j]=feature_space_linear_cka(embeddings[i],embeddings[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-27T15:33:23.293225Z",
     "iopub.status.busy": "2023-08-27T15:33:23.293054Z",
     "iopub.status.idle": "2023-08-27T15:33:23.296562Z",
     "shell.execute_reply": "2023-08-27T15:33:23.295905Z",
     "shell.execute_reply.started": "2023-08-27T15:33:23.293207Z"
    }
   },
   "outputs": [],
   "source": [
    "# fig,ax=plt.subplots(1,2,figsize=(20,10))\n",
    "# sns.heatmap(ckas_lin,annot=True,ax=ax[1])\n",
    "# sns.heatmap(ckas,annot=True,ax=ax[0])\n",
    "# plt.show()\n",
    "# for model_path,i in zip(ckpt_dirs,range(n_models)):\n",
    "#     print(model_path,std_of_l2_normalized(torch.Tensor(embeddings[i])))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
